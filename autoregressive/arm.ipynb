{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5afbcf6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "15d37fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode=\"train\", transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == \"train\":\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == \"val\":\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a50c532c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c35484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  5., 13.,  9.,  1.,  0.,  0.,  0.,  0., 13., 15., 10.,\n",
       "       15.,  5.,  0.,  0.,  3., 15.,  2.,  0., 11.,  8.,  0.,  0.,  4.,\n",
       "       12.,  0.,  0.,  8.,  8.,  0.,  0.,  5.,  8.,  0.,  0.,  9.,  8.,\n",
       "        0.,  0.,  4., 11.,  0.,  1., 12.,  7.,  0.,  0.,  2., 14.,  5.,\n",
       "       10., 12.,  0.,  0.,  0.,  0.,  6., 13., 10.,  0.,  0.,  0.],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b4d460c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x124ae50d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[5].reshape((8, 8)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "246273f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPS = 1.0e-5\n",
    "\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1.0 - EPS))\n",
    "    if reduction == \"avg\":\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7957f267",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ARM(nn.Module):\n",
    "    def __init__(self, net, D=2, num_vals=256):\n",
    "        super().__init__()\n",
    "        self.net = net\n",
    "        self.num_vals = num_vals\n",
    "        self.D = D\n",
    "\n",
    "    def f(self, x):\n",
    "        h = self.net(x.unsqueeze(1))\n",
    "        h = h.permute(0, 2, 1)\n",
    "        p = torch.softmax(h, 2)\n",
    "        return p\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        if reduction == 'avg':\n",
    "            return -(self.log_prob(x).mean())\n",
    "        elif reduction == \"sum\":\n",
    "            return -(self.log_prob(x).sum())\n",
    "        else:\n",
    "            raise ValueError('reduction could be either \"avg\" or \"sum\".')\n",
    "\n",
    "    def log_prob(self, x):\n",
    "        mu_d = self.f(x)\n",
    "        log_p = log_categorical(\n",
    "            x, mu_d, num_classes=self.num_vals, reduction=\"sum\", dim=-1\n",
    "        ).sum(-1)\n",
    "\n",
    "        return log_p\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        x_new = torch.zeros((batch_size, self.D))\n",
    "\n",
    "        for d in range(self.D):\n",
    "            p = self.f(x_new)\n",
    "            x_new_d = torch.multinomial(p[:, d, :], num_samples=1)\n",
    "            x_new[:, d] = x_new_d[:, 0]\n",
    "\n",
    "        return x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "967da1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + \".model\")\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.0\n",
    "    N = 0.0\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = model_best.forward(test_batch, reduction=\"sum\")\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f\"FINAL LOSS: nll={loss}\")\n",
    "    else:\n",
    "        print(f\"Epoch: {epoch}, val nll={loss}\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.savefig(name + \"_real_images.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=\"\"):\n",
    "    x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + \".model\")\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.savefig(name + \"_generated_images\" + extra_name + \".pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth=\"3\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"nll\")\n",
    "    plt.savefig(name + \"_nll_val_curve.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78cb549c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(\n",
    "    name, max_patience, num_epochs, model, optimizer, training_loader, val_loader\n",
    "):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.0\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            if hasattr(model, \"dequantization\"):\n",
    "                if model.dequantization:\n",
    "                    batch = batch + torch.rand(batch.shape)\n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print(\"saved!\")\n",
    "            torch.save(model, name + \".model\")\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print(\"saved!\")\n",
    "                torch.save(model, name + \".model\")\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78fd9f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Digits(mode=\"train\")\n",
    "val_data = Digits(mode=\"val\")\n",
    "test_data = Digits(mode=\"test\")\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "result_dir = \"results/\"\n",
    "if not (os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = \"arm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06b3f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64  # input dimension\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3  # learning rate\n",
    "num_epochs = 10  # max. number of epochs\n",
    "max_patience = 20  # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "651233b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CausalConv1d(nn.Module):\n",
    "    \"\"\"\n",
    "    A causal 1D convolution.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, in_channels, out_channels, kernel_size, dilation, A=False, **kwargs\n",
    "    ):\n",
    "        super(CausalConv1d, self).__init__()\n",
    "\n",
    "        # attributes:\n",
    "        self.kernel_size = kernel_size\n",
    "        self.dilation = dilation\n",
    "        self.A = A\n",
    "\n",
    "        self.padding = (kernel_size - 1) * dilation + A * 1\n",
    "\n",
    "        # module:\n",
    "        self.conv1d = torch.nn.Conv1d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            dilation=dilation,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.nn.functional.pad(x, (self.padding, 0))\n",
    "        conv1d_out = self.conv1d(x)\n",
    "        if self.A:\n",
    "            return conv1d_out[:, :, :-1]\n",
    "        else:\n",
    "            return conv1d_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6498e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "    CausalConv1d-1        [1, 256, 64]           2,048           2,048\n",
      "       LeakyReLU-2        [1, 256, 64]               0               0\n",
      "    CausalConv1d-3        [1, 256, 64]         459,008         459,008\n",
      "       LeakyReLU-4        [1, 256, 64]               0               0\n",
      "    CausalConv1d-5        [1, 256, 64]         459,008         459,008\n",
      "       LeakyReLU-6        [1, 256, 64]               0               0\n",
      "    CausalConv1d-7         [1, 17, 64]          30,481          30,481\n",
      "=======================================================================\n",
      "Total params: 950,545\n",
      "Trainable params: 950,545\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "likelihood_type = \"categorical\"\n",
    "\n",
    "num_vals = 17\n",
    "\n",
    "kernel = 7\n",
    "\n",
    "net = nn.Sequential(\n",
    "    CausalConv1d(\n",
    "        in_channels=1, out_channels=M, dilation=1, kernel_size=kernel, A=True, bias=True\n",
    "    ),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(\n",
    "        in_channels=M,\n",
    "        out_channels=M,\n",
    "        dilation=1,\n",
    "        kernel_size=kernel,\n",
    "        A=False,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(\n",
    "        in_channels=M,\n",
    "        out_channels=M,\n",
    "        dilation=1,\n",
    "        kernel_size=kernel,\n",
    "        A=False,\n",
    "        bias=True,\n",
    "    ),\n",
    "    nn.LeakyReLU(),\n",
    "    CausalConv1d(\n",
    "        in_channels=M,\n",
    "        out_channels=num_vals,\n",
    "        dilation=1,\n",
    "        kernel_size=kernel,\n",
    "        A=False,\n",
    "        bias=True,\n",
    "    ),\n",
    ")\n",
    "\n",
    "model = ARM(net, D=D, num_vals=num_vals)\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(summary(model, torch.zeros(1, 64), show_input=False, show_hierarchical=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "376d7808",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adamax(\n",
    "    [p for p in model.parameters() if p.requires_grad == True], lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "523dd618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=117.35728166852678\n",
      "saved!\n",
      "Epoch: 1, val nll=112.13411272321429\n",
      "saved!\n",
      "Epoch: 2, val nll=109.97497488839285\n",
      "saved!\n",
      "Epoch: 3, val nll=108.04765485491072\n",
      "saved!\n",
      "Epoch: 4, val nll=106.36564313616071\n",
      "saved!\n",
      "Epoch: 5, val nll=104.24338309151786\n",
      "saved!\n",
      "Epoch: 6, val nll=101.79314732142858\n",
      "saved!\n",
      "Epoch: 7, val nll=99.94033761160715\n",
      "saved!\n",
      "Epoch: 8, val nll=97.8099462890625\n",
      "saved!\n",
      "Epoch: 9, val nll=96.71830845424107\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "nll_val = training(\n",
    "    name=result_dir + name,\n",
    "    max_patience=max_patience,\n",
    "    num_epochs=num_epochs,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    training_loader=training_loader,\n",
    "    val_loader=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2af30ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=93.53871950153803\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + \"_test_loss.txt\", \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d915d902",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f594cfcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
