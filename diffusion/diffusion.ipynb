{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "469fa125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55a122a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = (\n",
    "        -0.5 * D * torch.log(2.0 * PI)\n",
    "        - 0.5 * log_var\n",
    "        - 0.5 * torch.exp(-log_var) * (x - mu) ** 2.0\n",
    "    )\n",
    "    if reduction == \"avg\":\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6e10605",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode=\"train\", transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == \"train\":\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == \"val\":\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c6006df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DDGM(nn.Module):\n",
    "    def __init__(self, p_dnns, decoder_net, beta, T, D):\n",
    "        super().__init__()\n",
    "        self.p_dnns = p_dnns\n",
    "        self.decoder_net = decoder_net\n",
    "        self.D = D\n",
    "        self.T = T\n",
    "        self.beta = torch.FloatTensor([beta])\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterization(mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def reparametrization_gaussian_diffusion(self, x, i):\n",
    "        return torch.sqrt(1. - self.beta) * x + torch.sqrt(self.beta) * torch.rand_like(x)\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        zs = [self.reparametrization_gaussian_diffusion(x, 0)]\n",
    "\n",
    "        mus = []\n",
    "        log_vars = []\n",
    "\n",
    "        for i in range(len(self.p_dnns) - 1, -1, -1):\n",
    "            h = self.p_dnns[i](zs[i+1])\n",
    "            mu_i, log_var_i = torch.chunk(h, 2, dim=1)\n",
    "            mus.append(mu_i)\n",
    "            log_vars.append(log_var_i)\n",
    "\n",
    "        mu_x = self.decoder_net(zs[0])\n",
    "\n",
    "        RE = log_normal_diag(x - mu_x).sum(-1)\n",
    "\n",
    "        KL = (log_normal_diag(zs[-1], torch.sqrt(1. - self.beta) * zs[-1], torch.log(self.beta)) - log_normal_diag(zs[-1])).sum(-1)\n",
    "\n",
    "        for i in range(len(mus)):\n",
    "            KL_i = (log_normal_diag(zs[i], torch.sqrt(1. - self.beta) * zs[i], torch.log(self.beta)) - log_normal_diag(zs[i], mus[i], log_vars[i])).sum(-1)\n",
    "\n",
    "            KL = KL + KL_i\n",
    "\n",
    "        if reduction == 'sum':\n",
    "            loss = -(RE - KL).sum()\n",
    "\n",
    "        else:\n",
    "            loss = -(RE - KL).mean()\n",
    "        return loss\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        z = torch.randn([batch_size, self.D])\n",
    "        for i in range(len(self.p_dnns) - 1, -1, -1):\n",
    "            h = self.p_dnns[i](z)\n",
    "            mu_i, log_var_i = torch.chunk(h, 2, dim=1)\n",
    "            z = self.reparameterization(torch.tanh(mu_i), log_var_i)\n",
    "            mu_x = self.decoder_net(z)\n",
    "            \n",
    "        return mu_x\n",
    "    \n",
    "    def sample_diffusion(self, x):\n",
    "        zs = [self.reparametrization_gaussian_diffusion(x, 0)]\n",
    "        for i in range(1, self.T):\n",
    "            zs.append(self.reparametrization_gaussian_diffusion(zs[-1], i))\n",
    "        return zs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c1f658",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
