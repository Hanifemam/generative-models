{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "812ee3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "# Ensure matplotlib can write cache files in restricted environments\n",
    "os.environ.setdefault(\"MPLCONFIGDIR\", \"./.matplotlib\")\n",
    "os.makedirs(os.environ[\"MPLCONFIGDIR\"], exist_ok=True)\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "933f216b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cd688982",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Digits(Dataset):\n",
    "\n",
    "    def __init__(self, mode=\"train\", transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == \"train\":\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == \"val\":\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = torch.tensor(self.data[idx], dtype=torch.float32)\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "21eba5c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 350)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = Digits()\n",
    "test_data = Digits(mode=\"val\")\n",
    "len(train_data), len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e879bee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3dfad593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.float64(-0.5), np.float64(7.5), np.float64(7.5), np.float64(-0.5))"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "img = train_data[random.choice(range(len(train_data)))].reshape((8,8))\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d26cd93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoG(nn.Module):\n",
    "    def __init__(self, D, K, uniform=False):\n",
    "        super(MoG, self).__init__()\n",
    "\n",
    "        # Hyperparameters\n",
    "        self.uniform = uniform\n",
    "        self.D = D\n",
    "        self.K = K\n",
    "\n",
    "        # Parameters\n",
    "        self.mu = nn.Parameter(torch.randn(1, self.K, self.D) * 0.25 + 0.5)\n",
    "        self.log_var = nn.Parameter(-3.0 * torch.ones(1, self.K, self.D))\n",
    "\n",
    "        if self.uniform:\n",
    "            self.w = torch.zeros(1, self.K)\n",
    "            self.w.requires_grad = False\n",
    "        else:\n",
    "            self.w = nn.Parameter(torch.zeros(1, self.K))\n",
    "        self.register_buffer(\"PI\", torch.tensor(np.pi))\n",
    "\n",
    "    def log_diag_normal(self, x, mu, log_var, reduction=\"sum\", dim=1):\n",
    "        log_p = (\n",
    "            -0.5 * torch.log(2.0 * self.PI)\n",
    "            - 0.5 * log_var\n",
    "            - 0.5 * torch.exp(-log_var) * (x.unsqueeze(1) - mu) ** 2.0\n",
    "        )\n",
    "        return log_p\n",
    "\n",
    "    def forward(self, x, reduction=\"mean\"):\n",
    "        log_pi = torch.log(\n",
    "            F.softmax(self.w, 1)\n",
    "        ) \n",
    "        log_N = torch.sum(self.log_diag_normal(x, self.mu, self.log_var), 2)\n",
    "        NLL_loss = -torch.logsumexp(log_pi + log_N, 1)  # B\n",
    "\n",
    "        if reduction == \"sum\":\n",
    "            return NLL_loss.sum()\n",
    "        elif reduction == \"mean\":\n",
    "            return NLL_loss.mean()\n",
    "        else:\n",
    "            raise ValueError(\"Either `sum` or `mean`.\")\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        x_sample = torch.empty(batch_size, self.D)\n",
    "\n",
    "        pi = F.softmax(\n",
    "            self.w, 1\n",
    "        )\n",
    "\n",
    "        indices = torch.multinomial(pi, batch_size, replacement=True).squeeze()\n",
    "\n",
    "        for n in range(batch_size):\n",
    "            indx = indices[n]\n",
    "            x_sample[n] = self.mu[0, indx] + torch.exp(\n",
    "                0.5 * self.log_var[0, indx]\n",
    "            ) * torch.randn(self.D)\n",
    "\n",
    "        return x_sample\n",
    "\n",
    "    def log_prob(self, x, reduction='mean'):\n",
    "        with torch.no_grad():\n",
    "            log_pi = torch.log(F.softmax(self.w, 1)) \n",
    "            log_N = torch.sum(self.log_diag_normal(x, self.mu, self.log_var), 2)  \n",
    "\n",
    "            log_prob = torch.logsumexp(log_pi + log_N,  1) \n",
    "\n",
    "            if reduction == 'sum':\n",
    "                return log_prob.sum()\n",
    "            elif reduction == 'mean':\n",
    "                return log_prob.mean()\n",
    "            else:\n",
    "                raise ValueError('Either `sum` or `mean`.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3988e3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def save_checkpoint(model, path):\n",
    "    torch.save(\n",
    "        {\n",
    "            'state_dict': model.state_dict(),\n",
    "            'D': model.D,\n",
    "            'K': model.K,\n",
    "            'uniform': model.uniform,\n",
    "        },\n",
    "        path,\n",
    "    )\n",
    "\n",
    "\n",
    "def load_checkpoint(path):\n",
    "    ckpt = torch.load(path, map_location='cpu')\n",
    "    if isinstance(ckpt, dict) and 'state_dict' in ckpt:\n",
    "        model = MoG(D=ckpt['D'], K=ckpt['K'], uniform=ckpt.get('uniform', False))\n",
    "        model.load_state_dict(ckpt['state_dict'])\n",
    "        return model\n",
    "    if isinstance(ckpt, MoG):\n",
    "        return ckpt\n",
    "    raise ValueError('Unexpected checkpoint format')\n",
    "\n",
    "\n",
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    if model_best is None:\n",
    "        model_best = load_checkpoint(name + \".model\")\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.0\n",
    "    N = 0.0\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = -model_best.log_prob(test_batch, reduction=\"sum\")\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f\"FINAL LOSS: nll={loss}\")\n",
    "    else:\n",
    "        print(f\"Epoch: {epoch}, val nll={loss}\")\n",
    "\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "6bf9c245",
   "metadata": {},
   "outputs": [],
   "source": [
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.savefig(name + \"_real_images.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "69b4bb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def samples_generated(name, data_loader, extra_name=\"\"):\n",
    "    with torch.no_grad():\n",
    "        # GENERATIONS-------\n",
    "        model_best = load_checkpoint(name + \".model\")\n",
    "\n",
    "        num_x = 4\n",
    "        num_y = 4\n",
    "        x = model_best.sample(batch_size=num_x * num_y)\n",
    "        x = x.detach().numpy()\n",
    "\n",
    "        fig, ax = plt.subplots(num_x, num_y)\n",
    "        for i, ax in enumerate(ax.flatten()):\n",
    "            plottable_image = np.reshape(x[i], (8, 8))\n",
    "            ax.imshow(plottable_image, cmap=\"gray\")\n",
    "            ax.axis(\"off\")\n",
    "\n",
    "        plt.savefig(\n",
    "            name + \"_generated_images\" + extra_name + \".pdf\", bbox_inches=\"tight\"\n",
    "        )\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd1f6dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth=\"3\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"nll\")\n",
    "    plt.savefig(name + \"_nll_val_curve.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "e5732e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\p'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\p'\n",
      "/tmp/ipython-input-657664620.py:16: SyntaxWarning: invalid escape sequence '\\p'\n",
      "  ax.set_title(f\"$\\pi$ = {pi[i].item():.5f}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def means_save(name, extra_name=\"\", num_x=4, num_y=4):\n",
    "    with torch.no_grad():\n",
    "        # GENERATIONS-------\n",
    "        model_best = load_checkpoint(name + \".model\")\n",
    "\n",
    "        pi = F.softmax(model_best.w, 1).squeeze()\n",
    "\n",
    "        x = model_best.mu[:, 0 : num_x * num_y]\n",
    "        N = x.shape[1]\n",
    "        x = x.squeeze(0).detach().numpy()\n",
    "\n",
    "        fig, ax = plt.subplots(int(np.sqrt(N)), int(np.sqrt(N)))\n",
    "        for i, ax in enumerate(ax.flatten()):\n",
    "            plottable_image = np.reshape(x[i], (8, 8))\n",
    "            ax.imshow(plottable_image, cmap=\"gray\")\n",
    "            ax.set_title(f\"$\\pi$ = {pi[i].item():.5f}\")\n",
    "            ax.axis(\"off\")\n",
    "        fig.tight_layout()\n",
    "        plt.savefig(name + \"_means_images\" + extra_name + \".pdf\", bbox_inches=\"tight\")\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "9db6bbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def training(\n",
    "    name, max_patience, num_epochs, model, optimizer, training_loader, val_loader\n",
    "):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.0\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print(\"saved!\")\n",
    "            save_checkpoint(model, name + \".model\")\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print(\"saved!\")\n",
    "                save_checkpoint(model, name + \".model\")\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "7af48cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def add_noise(x):\n",
    "    return x / 17.0 + torch.randn_like(x) / 136.0\n",
    "\n",
    "transforms = add_noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "a6a9a717",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Digits(mode=\"train\", transforms=transforms)\n",
    "val_data = Digits(mode=\"val\", transforms=transforms)\n",
    "test_data = Digits(mode=\"test\", transforms=transforms)\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "a501241a",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64  # input dimension\n",
    "\n",
    "K = 25  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3  # learning rate\n",
    "num_epochs = 100  # max. number of epochs\n",
    "max_patience = 20  # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2c4b03d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"mog\" + \"_\" + str(K)\n",
    "if not (os.path.exists(\"results/\")):\n",
    "    os.mkdir(\"results\")\n",
    "result_dir = \"results/\" + name + \"/\"\n",
    "if not (os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "2e1f2347",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MoG(D=D, K=K, uniform=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "54f84414",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(\n",
    "    [p for p in model.parameters() if p.requires_grad == True], lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "7b8f45f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=70.905517578125\n",
      "saved!\n",
      "Epoch: 1, val nll=60.159803292410714\n",
      "saved!\n",
      "Epoch: 2, val nll=50.68167759486607\n",
      "saved!\n",
      "Epoch: 3, val nll=42.62671282087054\n",
      "saved!\n",
      "Epoch: 4, val nll=35.953858816964285\n",
      "saved!\n",
      "Epoch: 5, val nll=30.3809619140625\n",
      "saved!\n",
      "Epoch: 6, val nll=25.73413312639509\n",
      "saved!\n",
      "Epoch: 7, val nll=21.77804443359375\n",
      "saved!\n",
      "Epoch: 8, val nll=18.405272391183036\n",
      "saved!\n",
      "Epoch: 9, val nll=15.488887677873883\n",
      "saved!\n",
      "Epoch: 10, val nll=12.9643603515625\n",
      "saved!\n",
      "Epoch: 11, val nll=10.753599679129465\n",
      "saved!\n",
      "Epoch: 12, val nll=8.890039934430803\n",
      "saved!\n",
      "Epoch: 13, val nll=7.281302664620536\n",
      "saved!\n",
      "Epoch: 14, val nll=5.892212088448661\n",
      "saved!\n",
      "Epoch: 15, val nll=4.653304661342076\n",
      "saved!\n",
      "Epoch: 16, val nll=3.5770477730887276\n",
      "saved!\n",
      "Epoch: 17, val nll=2.6272486005510602\n",
      "saved!\n",
      "Epoch: 18, val nll=1.7713522488730293\n",
      "saved!\n",
      "Epoch: 19, val nll=0.9826360511779785\n",
      "saved!\n",
      "Epoch: 20, val nll=0.2492590604509626\n",
      "saved!\n",
      "Epoch: 21, val nll=-0.40860964366367886\n",
      "saved!\n",
      "Epoch: 22, val nll=-1.0373923465183803\n",
      "saved!\n",
      "Epoch: 23, val nll=-1.616111627306257\n",
      "saved!\n",
      "Epoch: 24, val nll=-2.1577601337432863\n",
      "saved!\n",
      "Epoch: 25, val nll=-2.6940789903913225\n",
      "saved!\n",
      "Epoch: 26, val nll=-3.188231266566685\n",
      "saved!\n",
      "Epoch: 27, val nll=-3.6639193616594588\n",
      "saved!\n",
      "Epoch: 28, val nll=-4.093968778337751\n",
      "saved!\n",
      "Epoch: 29, val nll=-4.525100729806082\n",
      "saved!\n",
      "Epoch: 30, val nll=-4.939980948311942\n",
      "saved!\n",
      "Epoch: 31, val nll=-5.336979021344866\n",
      "saved!\n",
      "Epoch: 32, val nll=-5.725576934814453\n",
      "saved!\n",
      "Epoch: 33, val nll=-6.111037118094308\n",
      "saved!\n",
      "Epoch: 34, val nll=-6.463536551339286\n",
      "saved!\n",
      "Epoch: 35, val nll=-6.7890304129464285\n",
      "saved!\n",
      "Epoch: 36, val nll=-7.184333888462612\n",
      "saved!\n",
      "Epoch: 37, val nll=-7.478056248256139\n",
      "saved!\n",
      "Epoch: 38, val nll=-7.849739772251674\n",
      "saved!\n",
      "Epoch: 39, val nll=-8.133643580845424\n",
      "saved!\n",
      "Epoch: 40, val nll=-8.456341945103237\n",
      "saved!\n",
      "Epoch: 41, val nll=-8.759732971191406\n",
      "saved!\n",
      "Epoch: 42, val nll=-9.111181379045759\n",
      "saved!\n",
      "Epoch: 43, val nll=-9.42041996547154\n",
      "saved!\n",
      "Epoch: 44, val nll=-9.711852068219866\n",
      "saved!\n",
      "Epoch: 45, val nll=-9.981930454799107\n",
      "saved!\n",
      "Epoch: 46, val nll=-10.280562395368303\n",
      "saved!\n",
      "Epoch: 47, val nll=-10.573079354422433\n",
      "saved!\n",
      "Epoch: 48, val nll=-10.870604422433036\n",
      "saved!\n",
      "Epoch: 49, val nll=-11.155150669642858\n",
      "saved!\n",
      "Epoch: 50, val nll=-11.459843401227678\n",
      "saved!\n",
      "Epoch: 51, val nll=-11.67142796107701\n",
      "saved!\n",
      "Epoch: 52, val nll=-11.970619419642857\n",
      "saved!\n",
      "Epoch: 53, val nll=-12.224191371372768\n",
      "saved!\n",
      "Epoch: 54, val nll=-12.498134329659598\n",
      "saved!\n",
      "Epoch: 55, val nll=-12.710679844447546\n",
      "saved!\n",
      "Epoch: 56, val nll=-12.995504760742188\n",
      "saved!\n",
      "Epoch: 57, val nll=-13.235507114955357\n",
      "saved!\n",
      "Epoch: 58, val nll=-13.51150163922991\n",
      "saved!\n",
      "Epoch: 59, val nll=-13.75163356236049\n",
      "saved!\n",
      "Epoch: 60, val nll=-13.972781546456472\n",
      "saved!\n",
      "Epoch: 61, val nll=-14.291568952287946\n",
      "saved!\n",
      "Epoch: 62, val nll=-14.476839076450894\n",
      "saved!\n",
      "Epoch: 63, val nll=-14.717790091378347\n",
      "saved!\n",
      "Epoch: 64, val nll=-14.942464773995535\n",
      "saved!\n",
      "Epoch: 65, val nll=-15.201872035435267\n",
      "saved!\n",
      "Epoch: 66, val nll=-15.42296657017299\n",
      "saved!\n",
      "Epoch: 67, val nll=-15.687740391322544\n",
      "saved!\n",
      "Epoch: 68, val nll=-15.91521946498326\n",
      "saved!\n",
      "Epoch: 69, val nll=-16.137001865931918\n",
      "saved!\n",
      "Epoch: 70, val nll=-16.367400425502233\n",
      "saved!\n",
      "Epoch: 71, val nll=-16.565536324637275\n",
      "saved!\n",
      "Epoch: 72, val nll=-16.818753662109376\n",
      "saved!\n",
      "Epoch: 73, val nll=-17.047269112723214\n",
      "saved!\n",
      "Epoch: 74, val nll=-17.29218715122768\n",
      "saved!\n",
      "Epoch: 75, val nll=-17.48333243233817\n",
      "saved!\n",
      "Epoch: 76, val nll=-17.71920192173549\n",
      "saved!\n",
      "Epoch: 77, val nll=-17.917484566824776\n",
      "saved!\n",
      "Epoch: 78, val nll=-18.192001953125\n",
      "saved!\n",
      "Epoch: 79, val nll=-18.37758614676339\n",
      "saved!\n",
      "Epoch: 80, val nll=-18.61654541015625\n",
      "saved!\n",
      "Epoch: 81, val nll=-18.789713483537945\n",
      "saved!\n",
      "Epoch: 82, val nll=-19.02143258231027\n",
      "saved!\n",
      "Epoch: 83, val nll=-19.214594377790178\n",
      "saved!\n",
      "Epoch: 84, val nll=-19.467647879464284\n",
      "saved!\n",
      "Epoch: 85, val nll=-19.64869864327567\n",
      "saved!\n",
      "Epoch: 86, val nll=-19.896960972377233\n",
      "saved!\n",
      "Epoch: 87, val nll=-20.117997000558034\n",
      "saved!\n",
      "Epoch: 88, val nll=-20.303728724888394\n",
      "saved!\n",
      "Epoch: 89, val nll=-20.52206752232143\n",
      "saved!\n",
      "Epoch: 90, val nll=-20.67782540457589\n",
      "saved!\n",
      "Epoch: 91, val nll=-20.917188371930802\n",
      "saved!\n",
      "Epoch: 92, val nll=-21.165467878069197\n",
      "saved!\n",
      "Epoch: 93, val nll=-21.33686505998884\n",
      "saved!\n",
      "Epoch: 94, val nll=-21.519587925502233\n",
      "saved!\n",
      "Epoch: 95, val nll=-21.73378923688616\n",
      "saved!\n",
      "Epoch: 96, val nll=-21.949805385044645\n",
      "saved!\n",
      "Epoch: 97, val nll=-22.141143973214287\n",
      "saved!\n",
      "Epoch: 98, val nll=-22.3609375\n",
      "saved!\n",
      "Epoch: 99, val nll=-22.52138462611607\n",
      "saved!\n"
     ]
    }
   ],
   "source": [
    "nll_val = training(\n",
    "    name=result_dir + name,\n",
    "    max_patience=max_patience,\n",
    "    num_epochs=num_epochs,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    training_loader=training_loader,\n",
    "    val_loader=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "d88242cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=-24.652738771715953\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + \"_test_loss.txt\", \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "samples_generated(result_dir + name, test_loader, extra_name=\"FINAL\")\n",
    "\n",
    "means_save(result_dir + name, extra_name=\"_\" + str(K), num_x=5, num_y=5)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73824b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
