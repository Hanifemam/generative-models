{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1b7ada5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytorch_model_summary in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from pytorch_model_summary) (4.67.1)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from pytorch_model_summary) (2.9.0+cu126)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from pytorch_model_summary) (2.0.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->pytorch_model_summary) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->pytorch_model_summary) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->pytorch_model_summary) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_model_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "ecab158a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn import datasets\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from pytorch_model_summary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "2a707c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "PI = torch.from_numpy(np.asarray(np.pi))\n",
    "EPS = 1.0e-5\n",
    "\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1.0 - EPS))\n",
    "    if reduction == \"avg\":\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_bernoulli(x, p, reduction=None, dim=None):\n",
    "    pp = torch.clamp(p, EPS, 1.0 - EPS)\n",
    "    log_p = x * torch.log(pp) + (1.0 - x) * torch.log(1.0 - pp)\n",
    "    if reduction == \"avg\":\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_normal_diag(x, mu, log_var, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = (\n",
    "        -0.5 * D * torch.log(2.0 * PI)\n",
    "        - 0.5 * log_var\n",
    "        - 0.5 * torch.exp(-log_var) * (x - mu) ** 2.0\n",
    "    )\n",
    "    if reduction == \"avg\":\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_standard_normal(x, reduction=None, dim=None):\n",
    "    D = x.shape[1]\n",
    "    log_p = -0.5 * D * torch.log(2.0 * PI) - 0.5 * x**2.0\n",
    "    if reduction == \"avg\":\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ee837974",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Digits(Dataset):\n",
    "    \"\"\"Scikit-Learn Digits dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, mode=\"train\", transforms=None):\n",
    "        digits = load_digits()\n",
    "        if mode == \"train\":\n",
    "            self.data = digits.data[:1000].astype(np.float32)\n",
    "        elif mode == \"val\":\n",
    "            self.data = digits.data[1000:1350].astype(np.float32)\n",
    "        else:\n",
    "            self.data = digits.data[1350:].astype(np.float32)\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "27283d4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, encoder_net):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder_net\n",
    "\n",
    "    @staticmethod\n",
    "    def reparameterizing(mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "\n",
    "        return mu + std * eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        h_e = self.encoder(x)\n",
    "\n",
    "        mu_e, log_var_e = torch.chunk(h_e, 2, dim=1)\n",
    "        return mu_e, log_var_e\n",
    "\n",
    "    def sample(self, x=None, mu_e=None, log_var_e=None):\n",
    "        if (mu_e is None) and (log_var_e is None):\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "        return self.reparameterizing(mu_e, log_var_e)\n",
    "\n",
    "    def log_prob(self, x=None, mu_e=None, log_var_e=None, z=None):\n",
    "        # Reuse provided encoder stats when available to avoid re-encoding None\n",
    "        if (mu_e is None) or (log_var_e is None):\n",
    "            mu_e, log_var_e = self.encode(x)\n",
    "\n",
    "        if z is None:\n",
    "            z = self.sample(x, mu_e, log_var_e)\n",
    "\n",
    "        return log_normal_diag(z, mu_e, log_var_e)\n",
    "\n",
    "    def forward(self, x, type='log_prob'):\n",
    "        assert type in ['encode', 'log_prob'], 'Type could be either encode or log_prob'\n",
    "\n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x)\n",
    "        else:\n",
    "            return self.sample(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "1a7b4c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "\n",
    "    def __init__(self, decoder_net, distribution, num_vals):\n",
    "        super().__init__()\n",
    "        self.decoder = decoder_net\n",
    "        self.distribution = distribution\n",
    "        self.num_vals = num_vals\n",
    "\n",
    "    def decode(self, z):\n",
    "        h_d = self.decoder(z)\n",
    "        if self.distribution == 'categorical':\n",
    "            b = h_d.shape[0] # Batch size\n",
    "            d = h_d.shape[1] // self.num_vals # Dimensionality of x\n",
    "\n",
    "            h_d = h_d.view(b, d, self.num_vals)\n",
    "            mu_d = torch.softmax(h_d, 2)\n",
    "            return [mu_d]\n",
    "\n",
    "        elif self.distribution == 'bernoulli':\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "            return [mu_d]\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Only: categorical or bernulli')\n",
    "\n",
    "    def sample(self, z):\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == \"categorical\":\n",
    "            mu_d = outs[0]\n",
    "            b = mu_d.shape[0]  # Batch size\n",
    "            m = mu_d.shape[1]  # Dimensionality of x\n",
    "\n",
    "            mu_d = mu_d.view(mu_d.shape[0], -1, self.num_vals)\n",
    "            p = mu_d.view(-1, self.num_vals)\n",
    "\n",
    "            x_new = torch.multinomial(p, num_samples=1).view(b, m)\n",
    "\n",
    "        elif self.distribution == \"bernoulli\":\n",
    "            mu_d = outs[0]\n",
    "            x_new = torch.bernoulli(mu_d)\n",
    "\n",
    "        return x_new\n",
    "\n",
    "    def log_prob(self, x, z):\n",
    "        outs = self.decode(z)\n",
    "\n",
    "        if self.distribution == \"categorical\":\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
    "        elif self.distribution == \"bernoulli\":\n",
    "            mu_d = outs[0]\n",
    "            log_p = log_bernoulli(x, mu_d, reduction=\"sum\", dim=-1).sum(-1)\n",
    "        return log_p\n",
    "    \n",
    "    def forward(self, z, x=None, type='log_prob'):\n",
    "        assert type in ['decoder', 'log_prob'], 'Type could be either decode or log_prob'\n",
    "        \n",
    "        if type == 'log_prob':\n",
    "            return self.log_prob(x, z)\n",
    "        else:\n",
    "            return self.sample(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "4b709a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prior(nn.Module):\n",
    "    def __init__(self, L):\n",
    "        super(Prior, self).__init__()\n",
    "        self.L = L\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        z = torch.randn((batch_size, self.L))\n",
    "        return z\n",
    "\n",
    "    def log_prob(self, z):\n",
    "        return log_standard_normal(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3737d488",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_net,\n",
    "        decoder_net,\n",
    "        num_vals=256,\n",
    "        L=16,\n",
    "        likelihood_type=\"categorical\",\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = Encoder(encoder_net=encoder_net)\n",
    "        self.decoder = Decoder(distribution=likelihood_type, decoder_net=decoder_net, num_vals=num_vals)\n",
    "        self.prior = Prior(L=L)\n",
    "        \n",
    "        self.num_vals = num_vals\n",
    "        self.likelihood_tupe = likelihood_type\n",
    "        \n",
    "    def forward(self, x, reduction='avg'):\n",
    "        mu_e, log_var_e = self.encoder.encode(x)\n",
    "        z = self.encoder.sample(mu_e=mu_e, log_var_e=log_var_e)\n",
    "        \n",
    "        RE = self.decoder.log_prob(x, z)\n",
    "        KL = (self.prior.log_prob(z) - self.encoder.log_prob(mu_e=mu_e, log_var_e=log_var_e, z=z)).sum(-1)\n",
    "        \n",
    "        if reduction == 'sum':\n",
    "            return -(RE + KL).sum()\n",
    "        else:\n",
    "            return -(RE + KL).mean()\n",
    "        \n",
    "    def sample(self, batch_size=64):\n",
    "        z = self.prior.sample(batch_size=batch_size)\n",
    "        return self.decoder.sample(z)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "e44a6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(test_loader, name=None, model_best=None, epoch=None):\n",
    "    # EVALUATION\n",
    "    if model_best is None:\n",
    "        # load best performing model\n",
    "        model_best = torch.load(name + \".model\", weights_only=False)\n",
    "\n",
    "    model_best.eval()\n",
    "    loss = 0.0\n",
    "    N = 0.0\n",
    "    for indx_batch, test_batch in enumerate(test_loader):\n",
    "        loss_t = model_best.forward(test_batch, reduction=\"sum\")\n",
    "        loss = loss + loss_t.item()\n",
    "        N = N + test_batch.shape[0]\n",
    "    loss = loss / N\n",
    "\n",
    "    if epoch is None:\n",
    "        print(f\"FINAL LOSS: nll={loss}\")\n",
    "    else:\n",
    "        print(f\"Epoch: {epoch}, val nll={loss}\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def samples_real(name, test_loader):\n",
    "    # REAL-------\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = next(iter(test_loader)).detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.savefig(name + \"_real_images.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def samples_generated(name, data_loader, extra_name=\"\"):\n",
    "    x = next(iter(data_loader)).detach().numpy()\n",
    "\n",
    "    # GENERATIONS-------\n",
    "    model_best = torch.load(name + \".model\", weights_only=False)\n",
    "    model_best.eval()\n",
    "\n",
    "    num_x = 4\n",
    "    num_y = 4\n",
    "    x = model_best.sample(num_x * num_y)\n",
    "    x = x.detach().numpy()\n",
    "\n",
    "    fig, ax = plt.subplots(num_x, num_y)\n",
    "    for i, ax in enumerate(ax.flatten()):\n",
    "        plottable_image = np.reshape(x[i], (8, 8))\n",
    "        ax.imshow(plottable_image, cmap=\"gray\")\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    plt.savefig(name + \"_generated_images\" + extra_name + \".pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "def plot_curve(name, nll_val):\n",
    "    plt.plot(np.arange(len(nll_val)), nll_val, linewidth=\"3\")\n",
    "    plt.xlabel(\"epochs\")\n",
    "    plt.ylabel(\"nll\")\n",
    "    plt.savefig(name + \"_nll_val_curve.pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f70a2b7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(\n",
    "    name, max_patience, num_epochs, model, optimizer, training_loader, val_loader\n",
    "):\n",
    "    nll_val = []\n",
    "    best_nll = 1000.0\n",
    "    patience = 0\n",
    "\n",
    "    # Main loop\n",
    "    for e in range(num_epochs):\n",
    "        # TRAINING\n",
    "        model.train()\n",
    "        for indx_batch, batch in enumerate(training_loader):\n",
    "            if hasattr(model, \"dequantization\"):\n",
    "                if model.dequantization:\n",
    "                    batch = batch + torch.rand(batch.shape)\n",
    "            loss = model.forward(batch)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward(retain_graph=True)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        loss_val = evaluation(val_loader, model_best=model, epoch=e)\n",
    "        nll_val.append(loss_val)  # save for plotting\n",
    "\n",
    "        if e == 0:\n",
    "            print(\"saved!\")\n",
    "            torch.save(model, name + \".model\")\n",
    "            best_nll = loss_val\n",
    "        else:\n",
    "            if loss_val < best_nll:\n",
    "                print(\"saved!\")\n",
    "                torch.save(model, name + \".model\")\n",
    "                best_nll = loss_val\n",
    "                patience = 0\n",
    "\n",
    "                samples_generated(name, val_loader, extra_name=\"_epoch_\" + str(e))\n",
    "            else:\n",
    "                patience = patience + 1\n",
    "\n",
    "        if patience > max_patience:\n",
    "            break\n",
    "\n",
    "    nll_val = np.asarray(nll_val)\n",
    "\n",
    "    return nll_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "89d2bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = Digits(mode=\"train\")\n",
    "val_data = Digits(mode=\"val\")\n",
    "test_data = Digits(mode=\"test\")\n",
    "\n",
    "training_loader = DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=64, shuffle=False)\n",
    "\n",
    "result_dir = \"results/\"\n",
    "if not (os.path.exists(result_dir)):\n",
    "    os.mkdir(result_dir)\n",
    "name = \"vae\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "cc6ba25f",
   "metadata": {},
   "outputs": [],
   "source": [
    "D = 64  # input dimension\n",
    "L = 16  # number of latents\n",
    "M = 256  # the number of neurons in scale (s) and translation (t) nets\n",
    "\n",
    "lr = 1e-3  # learning rate\n",
    "num_epochs = 1000  # max. number of epochs\n",
    "max_patience = 20  # an early stopping is used, if training doesn't improve for longer than 20 epochs, it is stopped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "3e62306b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENCODER:\n",
      " -----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1            [1, 256]          16,640          16,640\n",
      "       LeakyReLU-2            [1, 256]               0               0\n",
      "          Linear-3            [1, 256]          65,792          65,792\n",
      "       LeakyReLU-4            [1, 256]               0               0\n",
      "          Linear-5             [1, 32]           8,224           8,224\n",
      "=======================================================================\n",
      "Total params: 90,656\n",
      "Trainable params: 90,656\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n",
      "\n",
      "DECODER:\n",
      " -----------------------------------------------------------------------\n",
      "      Layer (type)        Output Shape         Param #     Tr. Param #\n",
      "=======================================================================\n",
      "          Linear-1            [1, 256]           4,352           4,352\n",
      "       LeakyReLU-2            [1, 256]               0               0\n",
      "          Linear-3            [1, 256]          65,792          65,792\n",
      "       LeakyReLU-4            [1, 256]               0               0\n",
      "          Linear-5           [1, 1088]         279,616         279,616\n",
      "=======================================================================\n",
      "Total params: 349,760\n",
      "Trainable params: 349,760\n",
      "Non-trainable params: 0\n",
      "-----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "likelihood_type = \"categorical\"\n",
    "\n",
    "if likelihood_type == \"categorical\":\n",
    "    num_vals = 17\n",
    "elif likelihood_type == \"bernoulli\":\n",
    "    num_vals = 1\n",
    "\n",
    "encoder = nn.Sequential(\n",
    "    nn.Linear(D, M),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(M, M),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(M, 2 * L),\n",
    ")\n",
    "\n",
    "decoder = nn.Sequential(\n",
    "    nn.Linear(L, M),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(M, M),\n",
    "    nn.LeakyReLU(),\n",
    "    nn.Linear(M, num_vals * D),\n",
    ")\n",
    "\n",
    "prior = torch.distributions.MultivariateNormal(torch.zeros(L), torch.eye(L))\n",
    "model = VAE(\n",
    "    encoder_net=encoder,\n",
    "    decoder_net=decoder,\n",
    "    num_vals=num_vals,\n",
    "    L=L,\n",
    "    likelihood_type=likelihood_type,\n",
    ")\n",
    "\n",
    "# Print the summary (like in Keras)\n",
    "print(\n",
    "    \"ENCODER:\\n\",\n",
    "    summary(encoder, torch.zeros(1, D), show_input=False, show_hierarchical=False),\n",
    ")\n",
    "print(\n",
    "    \"\\nDECODER:\\n\",\n",
    "    summary(decoder, torch.zeros(1, L), show_input=False, show_hierarchical=False),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "6a9aa808",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adamax(\n",
    "    [p for p in model.parameters() if p.requires_grad == True], lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "641877aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, val nll=124.50018973214286\n",
      "saved!\n",
      "Epoch: 1, val nll=113.37462123325894\n",
      "saved!\n",
      "Epoch: 2, val nll=112.10539829799107\n",
      "saved!\n",
      "Epoch: 3, val nll=112.03906389508928\n",
      "saved!\n",
      "Epoch: 4, val nll=111.46582728794642\n",
      "saved!\n",
      "Epoch: 5, val nll=111.69710867745536\n",
      "Epoch: 6, val nll=111.51064104352679\n",
      "Epoch: 7, val nll=111.41423897879464\n",
      "saved!\n",
      "Epoch: 8, val nll=111.35100516183036\n",
      "saved!\n",
      "Epoch: 9, val nll=111.40824986049107\n",
      "Epoch: 10, val nll=111.40130161830358\n",
      "Epoch: 11, val nll=111.42490443638393\n",
      "Epoch: 12, val nll=111.14257184709821\n",
      "saved!\n",
      "Epoch: 13, val nll=111.29800851004464\n",
      "Epoch: 14, val nll=111.15116071428571\n",
      "Epoch: 15, val nll=111.18630161830357\n",
      "Epoch: 16, val nll=110.88647600446428\n",
      "saved!\n",
      "Epoch: 17, val nll=110.88691127232143\n",
      "Epoch: 18, val nll=111.05238560267857\n",
      "Epoch: 19, val nll=110.86848981584822\n",
      "saved!\n",
      "Epoch: 20, val nll=110.743720703125\n",
      "saved!\n",
      "Epoch: 21, val nll=110.90401925223215\n",
      "Epoch: 22, val nll=110.73096819196428\n",
      "saved!\n",
      "Epoch: 23, val nll=110.502900390625\n",
      "saved!\n",
      "Epoch: 24, val nll=110.22278878348214\n",
      "saved!\n",
      "Epoch: 25, val nll=109.79320103236607\n",
      "saved!\n",
      "Epoch: 26, val nll=109.77135672433036\n",
      "saved!\n",
      "Epoch: 27, val nll=109.64542271205357\n",
      "saved!\n",
      "Epoch: 28, val nll=109.19362583705357\n",
      "saved!\n",
      "Epoch: 29, val nll=108.90902064732143\n",
      "saved!\n",
      "Epoch: 30, val nll=108.34874720982143\n",
      "saved!\n",
      "Epoch: 31, val nll=108.27778878348214\n",
      "saved!\n",
      "Epoch: 32, val nll=107.82738560267858\n",
      "saved!\n",
      "Epoch: 33, val nll=106.95639857700893\n",
      "saved!\n",
      "Epoch: 34, val nll=106.94022321428571\n",
      "saved!\n",
      "Epoch: 35, val nll=106.36173828125\n",
      "saved!\n",
      "Epoch: 36, val nll=106.02776994977678\n",
      "saved!\n",
      "Epoch: 37, val nll=106.08881417410714\n",
      "Epoch: 38, val nll=106.03221261160714\n",
      "Epoch: 39, val nll=105.433212890625\n",
      "saved!\n",
      "Epoch: 40, val nll=105.64670549665179\n",
      "Epoch: 41, val nll=105.47480189732143\n",
      "Epoch: 42, val nll=105.21243722098214\n",
      "saved!\n",
      "Epoch: 43, val nll=105.01759835379464\n",
      "saved!\n",
      "Epoch: 44, val nll=104.66319056919643\n",
      "saved!\n",
      "Epoch: 45, val nll=104.45001883370536\n",
      "saved!\n",
      "Epoch: 46, val nll=104.62120744977679\n",
      "Epoch: 47, val nll=104.32318777901786\n",
      "saved!\n",
      "Epoch: 48, val nll=104.2165673828125\n",
      "saved!\n",
      "Epoch: 49, val nll=103.88569754464285\n",
      "saved!\n",
      "Epoch: 50, val nll=104.22254813058036\n",
      "Epoch: 51, val nll=103.82540666852678\n",
      "saved!\n",
      "Epoch: 52, val nll=103.5365478515625\n",
      "saved!\n",
      "Epoch: 53, val nll=103.3099951171875\n",
      "saved!\n",
      "Epoch: 54, val nll=103.64024972098214\n",
      "Epoch: 55, val nll=102.92793108258928\n",
      "saved!\n",
      "Epoch: 56, val nll=103.19320103236608\n",
      "Epoch: 57, val nll=103.19605259486607\n",
      "Epoch: 58, val nll=102.74633370535715\n",
      "saved!\n",
      "Epoch: 59, val nll=102.73823172433036\n",
      "saved!\n",
      "Epoch: 60, val nll=103.06762555803572\n",
      "Epoch: 61, val nll=102.73120675223214\n",
      "saved!\n",
      "Epoch: 62, val nll=102.81410295758928\n",
      "Epoch: 63, val nll=102.75576032366071\n",
      "Epoch: 64, val nll=102.74336495535714\n",
      "Epoch: 65, val nll=102.68033342633929\n",
      "saved!\n",
      "Epoch: 66, val nll=102.69796316964286\n",
      "Epoch: 67, val nll=102.68457101004465\n",
      "Epoch: 68, val nll=102.46955357142858\n",
      "saved!\n",
      "Epoch: 69, val nll=102.43306012834822\n",
      "saved!\n",
      "Epoch: 70, val nll=102.35376255580357\n",
      "saved!\n",
      "Epoch: 71, val nll=101.80006766183035\n",
      "saved!\n",
      "Epoch: 72, val nll=101.77316476004464\n",
      "saved!\n",
      "Epoch: 73, val nll=101.98146763392857\n",
      "Epoch: 74, val nll=101.9993212890625\n",
      "Epoch: 75, val nll=101.865263671875\n",
      "Epoch: 76, val nll=102.09358189174107\n",
      "Epoch: 77, val nll=101.80822405133928\n",
      "Epoch: 78, val nll=101.87526715959821\n",
      "Epoch: 79, val nll=101.9649853515625\n",
      "Epoch: 80, val nll=101.67225027901786\n",
      "saved!\n",
      "Epoch: 81, val nll=101.77794015066964\n",
      "Epoch: 82, val nll=101.39215053013393\n",
      "saved!\n",
      "Epoch: 83, val nll=101.94071149553571\n",
      "Epoch: 84, val nll=101.96329031808035\n",
      "Epoch: 85, val nll=101.99168387276785\n",
      "Epoch: 86, val nll=101.4545263671875\n",
      "Epoch: 87, val nll=101.60068638392858\n",
      "Epoch: 88, val nll=101.36670131138393\n",
      "saved!\n",
      "Epoch: 89, val nll=101.528955078125\n",
      "Epoch: 90, val nll=101.38706333705358\n",
      "Epoch: 91, val nll=101.64293875558036\n",
      "Epoch: 92, val nll=101.12328264508929\n",
      "saved!\n",
      "Epoch: 93, val nll=101.42330217633929\n",
      "Epoch: 94, val nll=101.65801339285714\n",
      "Epoch: 95, val nll=101.47111188616071\n",
      "Epoch: 96, val nll=101.48337262834822\n",
      "Epoch: 97, val nll=100.86454241071428\n",
      "saved!\n",
      "Epoch: 98, val nll=101.3022802734375\n",
      "Epoch: 99, val nll=101.10418038504464\n",
      "Epoch: 100, val nll=101.19214146205357\n",
      "Epoch: 101, val nll=101.03654645647322\n",
      "Epoch: 102, val nll=100.97950892857143\n",
      "Epoch: 103, val nll=101.08007672991072\n",
      "Epoch: 104, val nll=101.342744140625\n",
      "Epoch: 105, val nll=101.0172314453125\n",
      "Epoch: 106, val nll=101.17912248883928\n",
      "Epoch: 107, val nll=100.82640904017858\n",
      "saved!\n",
      "Epoch: 108, val nll=101.25749302455357\n",
      "Epoch: 109, val nll=101.320166015625\n",
      "Epoch: 110, val nll=101.32879464285715\n",
      "Epoch: 111, val nll=100.8869970703125\n",
      "Epoch: 112, val nll=101.05467145647322\n",
      "Epoch: 113, val nll=101.30363490513393\n",
      "Epoch: 114, val nll=101.02119698660714\n",
      "Epoch: 115, val nll=100.87696428571428\n",
      "Epoch: 116, val nll=101.10802385602679\n",
      "Epoch: 117, val nll=101.24847098214286\n",
      "Epoch: 118, val nll=101.2271826171875\n",
      "Epoch: 119, val nll=101.25761369977678\n",
      "Epoch: 120, val nll=101.35365304129465\n",
      "Epoch: 121, val nll=100.83027413504465\n",
      "Epoch: 122, val nll=101.07346958705357\n",
      "Epoch: 123, val nll=101.20291643415179\n",
      "Epoch: 124, val nll=101.44033621651786\n",
      "Epoch: 125, val nll=100.79880440848214\n",
      "saved!\n",
      "Epoch: 126, val nll=101.2157958984375\n",
      "Epoch: 127, val nll=101.06930873325892\n",
      "Epoch: 128, val nll=101.54782575334822\n",
      "Epoch: 129, val nll=101.3642041015625\n",
      "Epoch: 130, val nll=101.463798828125\n",
      "Epoch: 131, val nll=101.15301967075892\n",
      "Epoch: 132, val nll=100.93278180803571\n",
      "Epoch: 133, val nll=101.623740234375\n",
      "Epoch: 134, val nll=101.18700613839286\n",
      "Epoch: 135, val nll=100.8964306640625\n",
      "Epoch: 136, val nll=101.34013811383929\n",
      "Epoch: 137, val nll=101.54563058035714\n",
      "Epoch: 138, val nll=101.367490234375\n",
      "Epoch: 139, val nll=101.38082449776786\n",
      "Epoch: 140, val nll=101.411162109375\n",
      "Epoch: 141, val nll=101.31740862165178\n",
      "Epoch: 142, val nll=101.88536830357143\n",
      "Epoch: 143, val nll=101.69793108258929\n",
      "Epoch: 144, val nll=101.73684849330357\n",
      "Epoch: 145, val nll=101.98519810267857\n",
      "Epoch: 146, val nll=101.47752301897322\n"
     ]
    }
   ],
   "source": [
    "nll_val = training(\n",
    "    name=result_dir + name,\n",
    "    max_patience=max_patience,\n",
    "    num_epochs=num_epochs,\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    training_loader=training_loader,\n",
    "    val_loader=val_loader,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "543dfd6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINAL LOSS: nll=97.13310415792785\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluation(name=result_dir + name, test_loader=test_loader)\n",
    "f = open(result_dir + name + \"_test_loss.txt\", \"w\")\n",
    "f.write(str(test_loss))\n",
    "f.close()\n",
    "\n",
    "samples_real(result_dir + name, test_loader)\n",
    "\n",
    "plot_curve(result_dir + name, nll_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2b3a6c28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 8 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Draw 8 samples from the saved model\n",
    "model_best = torch.load(result_dir + name + \".model\", weights_only=False)\n",
    "model_best.eval()\n",
    "with torch.no_grad():\n",
    "    samples = model_best.sample(batch_size=8).detach().numpy()\n",
    "fig, axes = plt.subplots(2, 4, figsize=(8, 4))\n",
    "for ax, img in zip(axes.flatten(), samples):\n",
    "    ax.imshow(np.reshape(img, (8, 8)), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0212687c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
