{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a2243d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "PI = torch.from_numpy(np.asarray(np.pi))\n",
    "EPS = 1.0e-5\n",
    "\n",
    "def log_categorical(x, p, num_classes=256, reduction=None, dim=None):\n",
    "    x_one_hot = F.one_hot(x.long(), num_classes=num_classes)\n",
    "    log_p = x_one_hot * torch.log(torch.clamp(p, EPS, 1.0 - EPS))\n",
    "    if reduction == \"avg\":\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p\n",
    "\n",
    "\n",
    "def log_bernoulli(x, p, reduction=None, dim=None):\n",
    "    pp = torch.clamp(p, EPS, 1.0 - EPS)\n",
    "    log_p = x * torch.log(pp) + (1.0 - x) * torch.log(1.0 - pp)\n",
    "    if reduction == \"avg\":\n",
    "        return torch.mean(log_p, dim)\n",
    "    elif reduction == \"sum\":\n",
    "        return torch.sum(log_p, dim)\n",
    "    else:\n",
    "        return log_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c1bea17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalVAE(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nn_r_1,\n",
    "        nn_r_2,\n",
    "        nn_delta_1,\n",
    "        nn_delta_2,\n",
    "        nn_z_1,\n",
    "        nn_x,\n",
    "        D,\n",
    "        L,\n",
    "        num_vals,\n",
    "        likelihood_type,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Bottom-up\n",
    "        self.nn_r_1 = nn_r_1\n",
    "        self.nn_r_2 = nn_r_2\n",
    "\n",
    "        self.nn_delta_1 = nn_delta_1\n",
    "        self.nn_delta_2 = nn_delta_2\n",
    "\n",
    "        self.nn_z_1 = nn_z_1\n",
    "        self.nn_x = nn_x\n",
    "\n",
    "        self.D = D # input dimensionality\n",
    "\n",
    "        self.L = L # Second layer dimensionality\n",
    "\n",
    "        self.num_vals = num_vals\n",
    "\n",
    "        self.likelihood_type = likelihood_type\n",
    "\n",
    "    def reparameterization(self, mu, log_var):\n",
    "        std = torch.exp(0.5*log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + std * eps\n",
    "\n",
    "    def forward(self, x, reduction='avg'):\n",
    "        r_1 = self.nn_r_1(x)\n",
    "        r_2 = self.nn_r_2(r_1)\n",
    "\n",
    "        delta_1 = self.nn_delta_1(r_1)\n",
    "        delta_mu_1, delta_log_var_1 = torch.chunk(delta_1, 2, dim=1)\n",
    "\n",
    "        delta_log_var_1 = F.hardtanh(delta_log_var_1, -7., 2.)\n",
    "\n",
    "        delta_2 = self.nn_delta_2(r_2)\n",
    "        delta_mu_2, delta_log_var_2 = torch.chunk(delta_2, 2, dim=1)\n",
    "\n",
    "        delta_log_var_2 = F.hardtanh(delta_log_var_2, -7.0, 2.0)\n",
    "\n",
    "        z_2 = self.reparameterization(delta_mu_2, delta_log_var_2)\n",
    "\n",
    "        h_1 = self.nn_z_1(z_2)\n",
    "        mu_1, log_var_1 = torch.chunk(h_1, 2, dim=1)\n",
    "\n",
    "        z_1 = self.reparameterization(mu_1 + delta_mu_1, log_var_1 + delta_log_var_1)\n",
    "\n",
    "        h_d = self.nn_x(z_1)\n",
    "\n",
    "        if self.likelihood_type == 'categorical':\n",
    "            b = h_d.shape[0]\n",
    "            d = h_d.shape[1]//self.num_vals\n",
    "            h_d = h_d.view(b, d, self.num_vals)\n",
    "            mu_d = torch.softmax(h_d, 2)\n",
    "\n",
    "        elif self.likelihood_type == 'bernoulli':\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "\n",
    "        if self.likelihood_type == \"categorical\":\n",
    "            RE = log_categorical(x, mu_d, num_classes=self.num_vals, reduction='sum', dim=-1).sum(-1)\n",
    "\n",
    "        elif self.likelihood_type == \"bernoulli\":\n",
    "            RE = log_bernoulli(\n",
    "                x, mu_d, reduction=\"sum\", dim=-1\n",
    "            ).sum(-1)\n",
    "        KL_z_2 = 0.5 * (delta_mu_2 ** 2 + torch.exp(delta_log_var_2) - delta_log_var_2 - 1).sum(-1)\n",
    "        KL_z_1 = 0.5 * (\n",
    "            delta_mu_1**2 + torch.exp(delta_log_var_1) - delta_log_var_1 - 1\n",
    "        ).sum(-1)\n",
    "\n",
    "        KL = KL_z_1 + KL_z_2\n",
    "\n",
    "        if reduction == 'sum':\n",
    "            loss = -(RE - KL).sum()\n",
    "        else:\n",
    "            loss = -(RE - KL).mean()\n",
    "        return loss\n",
    "\n",
    "    def sample(self, batch_size=64):\n",
    "        z_2 = torch.randn(batch_size, self.L)\n",
    "        h_1 = self.nn_z_1(z_2)\n",
    "        mu_1, log_var_1 = torch.chunk(h_1, 2, dim=1)\n",
    "        z_1 = self.reparameterization(mu_1, log_var_1)\n",
    "        \n",
    "        h_d = self.nn_x(z_1)\n",
    "        if self.likelihood_type == \"categorical\":\n",
    "            b = batch_size\n",
    "            d = h_d.shape[1]//self.num_vals\n",
    "            h_d = h_d.view(b, d, self.num_vals)\n",
    "            mu_d = torch.softmax(h_d, 2)\n",
    "            \n",
    "            p = mu_d.view(-1, self.num_vals)\n",
    "            x_new = torch.multinomial(p, num_samples=1).view(b, d)\n",
    "\n",
    "        elif self.likelihood_type == \"bernoulli\":\n",
    "            mu_d = torch.sigmoid(h_d)\n",
    "            x_new = torch.bernoulli(mu_d)\n",
    "            \n",
    "        return x_new\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dc49d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
